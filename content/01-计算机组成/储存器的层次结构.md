今天开始，我们要进入到计算机另一个重要的组成部分，存储器。

如果你自己组装过PC机，你肯定知道，想要CPU，我们只要买一个就好了，但是存储器，却有不同的设备要买。比方说，我们要买内存，还要买硬盘。买硬盘的时候，不少人会买一块SSD硬盘作为系统盘，还会买上一块大容量的HDD机械硬盘作为数据盘。内存和硬盘都是我们的存储设备。而且，像硬盘这样的持久化存储设备，同时也是一个I/O设备。

在实际的软件开发过程中，我们常常会遇到服务端的请求响应时间长，吞吐率不够的情况。在分析对应问题的时候，相信你没少听过类似“主要瓶颈不在CPU，而在I/O”的论断。可见，存储在计算机中扮演着多么重要的角色。那接下来这一整个章节，我会为你梳理和讲解整个存储器系统。

这一讲，我们先从存储器的层次结构说起，让你对各种存储器设备有一个整体的了解。

#### 理解存储器的层次结构

在有计算机之前，我们通常把信息和数据存储在书、文件这样的物理介质里面。有了计算机之后，我们通常把数据存储在计算机的存储器里面。而存储器系统是一个通过各种不同的方法和设备，一层一层组合起来的系统。下面，我们把计算机的存储器层次结构和我们日常生活里处理信息、阅读书籍做个对照，好让你更容易理解、记忆存储器的层次结构。

我们常常把CPU比喻成计算机的“大脑”。我们思考的东西，就好比CPU中的寄存器（Register）。寄存器与其说是存储器，其实它更像是CPU本身的一部分，只能存放极其有限的信息，但是速度非常快，和CPU同步。

而我们大脑中的记忆，就好比CPU Cache（CPU高速缓存，我们常常简称为“缓存”）。CPU Cache用的是一种叫作SRAM（Static Random-Access Memory，静态随机存取存储器）的芯片。

#### SRAM

SRAM之所以被称为“静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。在SRAM里面，一个比特的数据，需要6～8个晶体管。所以SRAM的存储密度不高。同样的物理空间下，能够存储的数据有限。不过，因为SRAM的电路简单，所以访问速度非常快。

![sram](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi2chetv8yj31480t640i.jpg)

```
6个晶体管组成SRAM的一个比特
```

在CPU里，通常会有L1、L2、L3这样三层高速缓存。每个CPU核心都有一块属于自己的L1高速缓存，通常分成指令缓存和数据缓存，分开存放CPU使用的指令和数据。

不知道你还记不记得我们讲过的哈佛架构，这里的指令缓存和数据缓存，其实就是来自于哈佛架构。L1的Cache往往就嵌在CPU核心的内部。

L2的Cache同样是每个CPU核心都有的，不过它往往不在CPU核心的内部。所以，L2 Cache的访问速度会比L1稍微慢一些。而L3 Cache，则通常是多个CPU核心共用的，尺寸会更大一些，访问速度自然也就更慢一些。

你可以把CPU中的L1 Cache理解为我们的短期记忆，把L2/L3 Cache理解成长期记忆，把内存当成我们拥有的书架或者书桌。 当我们自己记忆中没有资料的时候，可以从书桌或者书架上拿书来翻阅。这个过程中就相当于，数据从内存中加载到CPU的寄存器和Cache中，然后通过“大脑”，也就是CPU，进行处理和运算。

#### DRAM

内存用的芯片和Cache有所不同，它用的是一种叫作DRAM（Dynamic Random Access Memory，动态随机存取存储器）的芯片，比起SRAM来说，它的密度更高，有更大的容量，而且它也比SRAM芯片便宜不少。

DRAM被称为“动态”存储器，是因为DRAM需要靠不断地“刷新”，才能保持数据被存储起来。DRAM的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM在同样的物理空间下，能够存储的数据也就更多，也就是存储的“密度”更大。但是，因为数据是存储在电容里的，电容会不断漏电，所以需要定时刷新充电，才能保持数据不丢失。DRAM的数据访问电路和刷新电路都比SRAM更复杂，所以访问延时也就更长.

![DRAM](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi2cl1ytxpj315g0csn13.jpg)

#### 存储器的层级结构

整个存储器的层次结构，其实都类似于SRAM和DRAM在性能和价格上的差异。SRAM更贵，速度更快。DRAM更便宜，容量更大。SRAM好像我们的大脑中的记忆，而DRAM就好像属于我们自己的书桌。

大脑（CPU）中的记忆（L1 Cache），不仅受成本层面的限制，更受物理层面的限制。这就好比L1 Cache不仅昂贵，其访问速度和它到CPU的物理距离有关。芯片造得越大，总有部分离CPU的距离会变远。电信号的传输速度又受物理原理的限制，没法超过光速。所以想要快，并不是靠多花钱就能解决的。

我们自己的书房和书桌（也就是内存）空间一般是有限的，没有办法放下所有书（也就是数据）。如果想要扩大空间的话，就相当于要多买几平方米的房子，成本就会很高。于是，想要放下更多的书，我们就要寻找更加廉价的解决方案。

没错，我们想到了公共图书馆。对于内存来说，SSD（Solid-state drive或Solid-state disk，固态硬
盘）、HDD（Hard Disk Drive，硬盘）这些被称为硬盘的外部存储设备，就是公共图书馆。于是，我们就可以去家附近的图书馆借书了。图书馆有更多的空间（存储空间）和更多的书（数据）。
你应该也在自己的个人电脑上用过SSD硬盘。过去几年，SSD这种基于NAND芯片的高速硬盘，价格已经大幅度下降。

而HDD硬盘则是一种完全符合“磁盘”这个名字的传统硬件。“磁盘”的硬件结构，决定了它的访问速度
受限于它的物理结构，是最慢的。

这些我们后面都会详细说，你可以对照下面这幅图了解一下，对存储器层次之间的作用和关联有个大致印象就可以了。

![RAM](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi2cnur0faj311i0n2ag5.jpg)

从Cache、内存，到SSD和HDD硬盘，一台现代计算机中，就用上了所有这些存储器设备。其中，容量越小的设备速度越快，而且，CPU并不是直接和每一种存储器设备打交道，而是每一种存储器设备，只和它相邻的存储设备打交道。比如，CPU Cache是从内存里加载而来的，或者需要写回内存，并不会直接写回数据到硬盘，也不会直接从硬盘加载数据到CPU Cache中，而是先加载到内存，再从内存加载到Cache中。

这样，各个存储器只和相邻的一层存储器打交道，并且随着一层层向下，存储器的容量逐层增大，访问速度逐层变慢，而单位存储成本也逐层下降，也就构成了我们日常所说的存储器层次结构。

### 局部性原理

平时进行服务端软件开发的时候，我们通常会把数据存储在数据库里。而服务端系统遇到的第一个性能瓶颈，往往就发生在访问数据库的时候。这个时候，大部分工程师和架构师会拿出一种叫作“缓存”的武器，通过使用Redis或者Memcache这样的开源软件，在数据库前面提供一层缓存的数据，来缓解数据库面临的压力，提升服务端的程序性能。

![局部性0](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi5s6o76f4j313k0lm0yu.jpg)

那么，不知道你有没有想过，这种添加缓存的策略一定是有效的吗？或者说，这种策略在什么情况下是有效的呢？如果从理论角度去分析，添加缓存一定是我们的最佳策略么？进一步地，如果我们对于访问性能的要求非常高，希望数据在1毫秒，乃至100微妙内完成处理，我们还能用这个添加缓存的策略么？

#### 理解局部性原理

我们先来回顾一下，上一讲的这张不同存储器的性能和价目表。可以看到，不同的存储器设备之间，访问速度、价格和容量都有几十乃至上千倍的差异。

![局部性1](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi5sa98qm5j313o0ksaem.jpg)

以Intel 8265U的CPU为例，它的L1 Cache只有256K，L2 Cache有个1MB，L3 Cache有12MB。一共13MB的存储空间，如果按照7美元/1MB的价格计算，就要91美元。

我们的内存有8GB，容量是CPU Cache的600多倍，按照表上的价格差不多就是120美元。如果按照今天京东上的价格，恐怕不到40美元。128G的SSD和1T的HDD，现在的价格加起来也不会超过100美元。虽然容量是内存的16倍乃至128倍，但是它们的访问速度却不到内存的1/1000。

性能和价格的巨大差异，给我们工程师带来了一个挑战：我们能不能既享受CPU Cache的速度，又享受内存、硬盘巨大的容量和低廉的价格呢？

好了，现在我公布答案。想要同时享受到这三点，前辈们已经探索出了答案，那就是，存储器中数据的局部性原理（Principle of Locality）。我们可以利用这个局部性原理，来制定管理和访问数据的策略。这个局部性原理包括时间局部性（temporal locality）和空间局部性（spatial locality）这两种策略。

我们先来看时间局部性。这个策略是说，如果一个数据被访问了，那么它在短时间内还会被再次访问。这么看这个策略有点奇怪是吧？我用一个简单的例子给你解释下，你一下就能明白了。

比如说，《哈利波特与魔法石》这本小说，我今天读了一会儿，没读完，明天还会继续读。同理，在一个电子商务型系统中，如果一个用户打开了App，看到了首屏。我们推断他应该很快还会再次访问网站的其他内容或者页面，我们就将这个用户的个人信息，从存储在硬盘的数据库读取到内存的缓存中来。这利用的就是时间局部性。

![局部性2](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi5scv5ys6j31380nsq5v.jpg)



我们再来看**空间局部性**。这个策略是说，如果一个数据被访问了，那么和它相邻的数据也很快会被访问。

我们还拿刚才读《哈利波特与魔法石》的例子来说。我读完了这本书之后，感觉这书不错，所以就会借阅整套“哈利波特”。这就好比我们的程序，在访问了数组的首项之后，多半会循环访问它的下一项。因为，在存储数据的时候，数组内的多项数据会存储在相邻的位置。这就好比图书馆会把“哈利波特”系列放在一个书架上，摆放在一起，加载的时候，也会一并加载。我们去图书馆借书，往往会一次性把7本都借回来。

![局部性3](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi5sepwe63j312c0n2tbg.jpg)

有了时间局部性和空间局部性，我们不用再把所有数据都放在内存里，也不用都放在HDD硬盘上，而是把访问次数多的数据，放在贵但是快一点的存储器里，把访问次数少的数据，放在慢但是大一点的存储器里。

这样组合使用内存、SSD硬盘以及HDD硬盘，使得我们可以用最低的成本提供实际所需要的数据存储、管理和访问的需求。

















